{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.rxn_ctr_mcs import *\n",
    "from src.utils import load_json, rxn_entry_to_smarts, rm_atom_map_num\n",
    "from src.pathway_utils import get_reverse_paths_to_starting, create_graph_from_pickaxe\n",
    "from src.post_processing import *\n",
    "\n",
    "from minedatabase.pickaxe import Pickaxe\n",
    "from minedatabase.utils import get_compound_hash\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Intializing pickaxe object\n",
      "\n",
      "Done intializing pickaxe object\n",
      "----------------------------------------\n",
      "\n",
      "Loading ../data/raw_expansions/ccm_v0_to_hopa_gen_2_tan_sample_1_n_samples_1000.pk pickled data.\n",
      "Loaded 3604 operators\n",
      "Loaded 1 targets\n",
      "Took 2.0639290809631348\n"
     ]
    }
   ],
   "source": [
    "# Set params\n",
    "\n",
    "expansion_dir = '../data/raw_expansions/'\n",
    "starters = 'ccm_v0'\n",
    "targets = 'hopa'\n",
    "generations = 2\n",
    "fn = f\"{starters}_to_{targets}_gen_{generations}_tan_sample_1_n_samples_1000.pk\" # Expansion file name\n",
    "\n",
    "# Load raw expansion object\n",
    "pk = Pickaxe()\n",
    "path = expansion_dir + fn\n",
    "pk.load_pickled_pickaxe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial graph\n",
    "\n",
    "DG, rxn, edge = create_graph_from_pickaxe(pk, \"Biology\")\n",
    "starting_nodes = []\n",
    "bad_nodes = []\n",
    "for n in DG.nodes():\n",
    "    try:\n",
    "        if DG.nodes()[n][\"Type\"] == \"Starting Compound\":\n",
    "            starting_nodes.append(n)\n",
    "    except:\n",
    "        bad_nodes.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pathways\n",
    "max_depth = generations * 2\n",
    "paths = defaultdict(list)\n",
    "\n",
    "# Specify Targets / Starting Cpds\n",
    "# target_cids = [get_compound_hash(smi)[0] for smi in pk.target_smiles]\n",
    "# target_names = [target_smi_name.loc[smi, \"id\"] for smi in pk.target_smiles]\n",
    "target_cids, target_names = [], []\n",
    "for k,v in pk.targets.items():\n",
    "    target_cids.append(get_compound_hash(v['SMILES'])[0])\n",
    "    target_names.append(v['ID'])\n",
    "\n",
    "starting_cpds = [get_compound_hash(val[\"SMILES\"])[0] for val in pk.compounds.values() if val[\"Type\"].startswith(\"Start\")]\n",
    "\n",
    "# Loop through targets and get pathways from targets to starting compounds\n",
    "for i, this_target in enumerate(target_cids):\n",
    "    this_paths = get_reverse_paths_to_starting(DG, begin_node=this_target, end_nodes=starting_cpds, max_depth=max_depth)\n",
    "    # If we find paths then reverse those paths and assign to a dictionary\n",
    "    if this_paths:\n",
    "        this_paths = list(set([tuple(path[1::2]) for path in [[*reversed(ind_path)] for ind_path in this_paths]]))\n",
    "        for elt in this_paths:\n",
    "            for r in pk.reactions[elt[0]][\"Reactants\"]:\n",
    "                if r[-1] in starting_cpds:\n",
    "                    s_name = pk.compounds[r[-1]][\"ID\"]\n",
    "                    t_name = target_names[i]\n",
    "                    paths[(s_name, t_name)].append(pathway(rhashes=elt, starter_hash=r[-1], target_hash=this_target)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predicted reaction dict\n",
    "\n",
    "pred_rxns = {}\n",
    "degen_rhashes = defaultdict(lambda : 1)\n",
    "for st_pair in paths:\n",
    "    for elt in paths[st_pair]:\n",
    "        for this_rhash in elt.rhashes:\n",
    "            if this_rhash not in pred_rxns:\n",
    "                rxn_sma = rxn_hash_2_rxn_sma(this_rhash, pk)\n",
    "                pred_rxns[this_rhash] = reaction(this_rhash, rxn_sma)\n",
    "            else:\n",
    "                degen_rhashes[this_rhash] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in paths.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in IMT rule mapping\n",
    "\n",
    "# Load rules\n",
    "rules_path = '../data/rules/JN3604IMT_rules.tsv'\n",
    "rule_df = pd.read_csv(rules_path, delimiter='\\t')\n",
    "rule_df.set_index('Name', inplace=True)\n",
    "\n",
    "# Load mapping\n",
    "rxn2rule = {}\n",
    "db_names = ['_mc_v21', '_brenda', '_kegg']\n",
    "suffix = '_imt_rules_enforce_cof.csv'\n",
    "for name in db_names:\n",
    "    mapping_path = '../data/mapping/mapping' + name + suffix\n",
    "    with open(mapping_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) == 1:\n",
    "                rxn2rule[row[0]] = []\n",
    "            else:\n",
    "                rxn2rule[row[0]] = row[1:]\n",
    "\n",
    "# Make rule2rxn\n",
    "rule2rxn = {}\n",
    "for k,v in rxn2rule.items():\n",
    "    for elt in v:\n",
    "        if elt not in rule2rxn:\n",
    "            rule2rxn[elt] = [k]\n",
    "        else:\n",
    "            rule2rxn[elt].append(k)\n",
    "\n",
    "# Load all known reaction json entries into dict\n",
    "known_rxns = {}\n",
    "pref = '../data/mapping/'\n",
    "suffs = ['mc_v21_as_is.json', 'brenda_as_is.json', 'kegg_as_is.json']\n",
    "for elt in suffs:\n",
    "    known_rxns.update(load_json(pref + elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate reaction objects in rxn dict w/ known reactions\n",
    "\n",
    "for k, v in pred_rxns.items():\n",
    "    this_rules = list(pk.reactions[k][\"Operators\"])\n",
    "    this_known_rxns = []\n",
    "    for elt in this_rules:\n",
    "        if elt in rule2rxn:\n",
    "            this_rxn_ids = rule2rxn[elt]\n",
    "            for this_id in this_rxn_ids:\n",
    "                this_sma = rxn_entry_to_smarts(known_rxns[this_id])\n",
    "                this_known_rxns.append((None, this_sma, this_id))\n",
    "    \n",
    "    v.known_rxns = [list(elt) for elt in set(this_known_rxns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_rxns))\n",
    "for k,v in paths.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_am_errors = [] # Track predicted rxn am errors\n",
    "kr_am_errors = [] # Track known rxn am errors\n",
    "alignment_issues = [] # Track substrate alignment issues\n",
    "\n",
    "# Populate pred_rxns, known rxn prc-mcs slot\n",
    "for x in range(len(pred_rxns.keys())):\n",
    "    h = list(pred_rxns.keys())[x]\n",
    "    rxn_sma1 = pred_rxns[h].smarts\n",
    "\n",
    "    # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "    try:\n",
    "        am_rxn_sma1 = atom_map(rxn_sma1)\n",
    "    except:\n",
    "        pr_am_errors.append(h)\n",
    "        continue\n",
    "\n",
    "    a = 0 # Number known rxns analyzed\n",
    "    for z, kr in enumerate(pred_rxns[h].known_rxns):\n",
    "        rxn_sma2 = kr[1]\n",
    "\n",
    "        # Catch stoichiometry mismatches stemming from pickaxe, early post-processing\n",
    "        if tuple([len(elt.split('.')) for elt in rxn_sma2.split('>>')]) != tuple([len(elt.split('.')) for elt in rxn_sma1.split('>>')]):\n",
    "            print(x, z, 'stoich_error')\n",
    "            continue\n",
    "\n",
    "        # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "        try:\n",
    "            am_rxn_sma2 = atom_map(rxn_sma2)\n",
    "        except:\n",
    "            kr_am_errors.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # Construct reaction objects\n",
    "        rxns = []\n",
    "        for elt in [am_rxn_sma1, am_rxn_sma2]:\n",
    "            temp = AllChem.ReactionFromSmarts(elt, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns.append(temp)\n",
    "\n",
    "        rc_atoms = [elt.GetReactingAtoms() for elt in rxns] # Get reaction center atom idxs\n",
    "\n",
    "        # Construct rxn ctr mol objs\n",
    "        try: # REMOVE after addressing KekulizationException in get_sub_mol\n",
    "            rcs = []\n",
    "            for i, t_rxn in enumerate(rxns):\n",
    "                temp = []\n",
    "                for j, t_mol in enumerate(t_rxn.GetReactants()):\n",
    "                    temp.append(get_sub_mol(t_mol, rc_atoms[i][j]))\n",
    "                rcs.append(temp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Align substrates of the 2 reactions\n",
    "        rc_idxs = [] # Each element: (idx for rxn 1, idx for rxn 2)\n",
    "        remaining = [[i for i in range(len(elt))] for elt in rcs]\n",
    "        while (len(remaining[0]) > 0) & (len(remaining[1]) > 0):\n",
    "            idx_pair = align_substrates(rcs, remaining)\n",
    "\n",
    "            if idx_pair is None:\n",
    "                break\n",
    "            else:\n",
    "                rc_idxs.append(idx_pair)\n",
    "                remaining[0].remove(idx_pair[0])\n",
    "                remaining[1].remove(idx_pair[1])\n",
    "\n",
    "        # Skip if you haven't aligned every reactant pred to known\n",
    "        if len(rc_idxs) < len(rxn_sma1.split('>>')[0].split('.')):\n",
    "            alignment_issues.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # For reaction 2 (known reaction) Re-order rcs, rc_atoms,\n",
    "        # internal order of reactants in the reaction object in rxns\n",
    "        # and the smarts stored in the known_reactions attribute of the\n",
    "        # associated predicted reaction\n",
    "\n",
    "        # Sort reaction 2 rc_idxs by reaction 1 rc_idxs\n",
    "        rxn_1_rc_idxs, rxn_2_rc_idxs = list(zip(*rc_idxs))\n",
    "        if rxn_1_rc_idxs != rxn_2_rc_idxs:\n",
    "            rxn_2_rc_idxs, rxn_1_rc_idxs = sort_x_by_y(rxn_2_rc_idxs, rxn_1_rc_idxs)\n",
    "\n",
    "            # Re-order atom-mapped smarts string, and then update known_rxns entry\n",
    "            # with de-atom-mapped version of this string because atom mapper changes\n",
    "            # reactant order and its this order that rcs, rcatoms, rc_idxs all come from\n",
    "            am_ro_sma2 = am_rxn_sma2.split('>>')[0].split('.') # Get list of reactant strings\n",
    "            am_ro_sma2 = '.'.join([am_ro_sma2[elt] for elt in rxn_2_rc_idxs]) # Re-join in new order\n",
    "            am_rxn_sma2 = am_ro_sma2 + '>>' + am_rxn_sma2.split('>>')[1] # Join with products side\n",
    "\n",
    "            # Re-construct reaction object from re-ordered, am smarts\n",
    "            foo = rxns[1]\n",
    "            temp = AllChem.ReactionFromSmarts(am_rxn_sma2, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns[1] = temp\n",
    "            bar = rxns[1]\n",
    "\n",
    "            rc_atoms[1] = rxns[1].GetReactingAtoms() # Update rc_atoms\n",
    "            rcs[1] = [get_sub_mol(elt, rc_atoms[1][i]) for i, elt in enumerate(rxns[1].GetReactants())] # Update rc mol obj\n",
    "        \n",
    "        pred_rxns[h].known_rxns[z][1] = rm_atom_map_num(am_rxn_sma2) # Update known_reaction entry w/ de-am smarts\n",
    "        rxns = align_atom_map_nums(rxns, rcs, rc_atoms)\n",
    "\n",
    "        # Compute MCS seeded by reaction center\n",
    "        prc_mcs = get_prc_mcs(rxns, rcs, rc_atoms) \n",
    "        pred_rxns[h].known_rxns[z][0] = prc_mcs # Update pred_rxns\n",
    "        \n",
    "        a += 1 # Count known rxn analyzed\n",
    "        pred_rxns[h].smarts = rm_atom_map_num(am_rxn_sma1) # Update pred_rxn smarts w/ de-am smarts\n",
    "\n",
    "    print(x, ':', a / (z+1), 'of', z+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reactions dict and paths list (ultimately will replace with expansion object)\n",
    "\n",
    "rxns_fn = 'predicted_reactions_' + fn\n",
    "paths_fn = 'paths_' + fn\n",
    "save_dir = '../data/processed_expansions/'\n",
    "rxns_path = save_dir + rxns_fn\n",
    "paths_path = save_dir + paths_fn\n",
    "\n",
    "with open(rxns_path, 'wb') as f:\n",
    "    pickle.dump(pred_rxns, f)\n",
    "\n",
    "with open(paths_path, 'wb') as f:\n",
    "    pickle.dump(paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(alignment_issues), len(pr_am_errors), len(kr_am_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
