{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stef/miniconda3/envs/mine/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at /home/stef/miniconda3/envs/mine/lib/python3.7/site-packages/rxnmapper/models/transformers/albert_heads_8_uspto_all_1310k were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.rxn_ctr_mcs import *\n",
    "from src.utils import load_json, rxn_entry_to_smarts, rm_atom_map_num\n",
    "from src.pathway_utils import get_reverse_paths_to_starting, create_graph_from_pickaxe\n",
    "from src.post_processing import *\n",
    "\n",
    "from minedatabase.pickaxe import Pickaxe\n",
    "from minedatabase.utils import get_compound_hash\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Intializing pickaxe object\n",
      "\n",
      "Done intializing pickaxe object\n",
      "----------------------------------------\n",
      "\n",
      "Loading ../data/pruned_expansions/2mg_to_mvacid_gen_2_tan_sample_1_n_samples_1000.pk pickled data.\n",
      "Loaded 18 compounds\n",
      "Loaded 15 reactions\n",
      "Loaded 3604 operators\n",
      "Loaded 1 targets\n",
      "Took 3.520051956176758\n"
     ]
    }
   ],
   "source": [
    "# Load processed expansion\n",
    "starters = '2mg'\n",
    "targets = 'mvacid'\n",
    "generations = 2\n",
    "\n",
    "expansion_dir = '../data/processed_expansions/'\n",
    "thermo_dir = '../data/thermo/'\n",
    "fn = f\"{starters}_to_{targets}_gen_{generations}_tan_sample_1_n_samples_1000.pk\" # Expansion file name\n",
    "rxns_path = expansion_dir + 'predicted_reactions_' + fn\n",
    "paths_path = expansion_dir + 'paths_' + fn\n",
    "pruned_dir = '../data/pruned_expansions/'\n",
    "\n",
    "# Load reactions and paths\n",
    "with open(rxns_path, 'rb') as f:\n",
    "    pred_rxns = pickle.load(f)\n",
    "\n",
    "with open(paths_path, 'rb') as f:\n",
    "    paths = pickle.load(f)\n",
    "\n",
    "# Load raw expansion object\n",
    "pk = Pickaxe()\n",
    "path = pruned_dir + fn\n",
    "pk.load_pickled_pickaxe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "('2mg', 'mvacid') 15\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_rxns))\n",
    "for k,v in paths.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.975609756097561 of 41\n",
      "1 : 1.0 of 28\n",
      "2 : 1.0 of 28\n",
      "3 : 0.975609756097561 of 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : 0.0 of 92\n",
      "6 : 0.4 of 50\n",
      "7 : 0.6086956521739131 of 23\n",
      "8 : 1.0 of 10\n",
      "9 : 0.9649122807017544 of 57\n",
      "10 : 1.0 of 7\n",
      "11 : 1.0 of 21\n",
      "12 : 1.0 of 21\n",
      "13 : 0.42857142857142855 of 56\n",
      "14 : 0.6533333333333333 of 75\n"
     ]
    }
   ],
   "source": [
    "pr_am_errors = [] # Track predicted rxn am errors\n",
    "kr_am_errors = [] # Track known rxn am errors\n",
    "alignment_issues = [] # Track substrate alignment issues\n",
    "norm = 'max atoms' # Normalize MCS atom count by larger molecule\n",
    "\n",
    "# Populate pred_rxns, known rxn prc-mcs slot\n",
    "for x in range(len(pred_rxns.keys())):\n",
    "    h = list(pred_rxns.keys())[x]\n",
    "    rxn_sma1 = pred_rxns[h].smarts\n",
    "\n",
    "    # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "    try:\n",
    "        am_rxn_sma1 = atom_map(rxn_sma1)\n",
    "    except:\n",
    "        pr_am_errors.append(h)\n",
    "        continue\n",
    "\n",
    "    a = 0 # Number known rxns analyzed\n",
    "    for z, kr in enumerate(pred_rxns[h].known_rxns):\n",
    "        rxn_sma2 = kr[1]\n",
    "\n",
    "        # Catch stoichiometry mismatches stemming from pickaxe, early post-processing\n",
    "        if tuple([len(elt.split('.')) for elt in rxn_sma2.split('>>')]) != tuple([len(elt.split('.')) for elt in rxn_sma1.split('>>')]):\n",
    "            print(x, z, 'stoich_error')\n",
    "            continue\n",
    "\n",
    "        # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "        try:\n",
    "            am_rxn_sma2 = atom_map(rxn_sma2)\n",
    "        except:\n",
    "            kr_am_errors.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # Construct reaction objects\n",
    "        rxns = []\n",
    "        for elt in [am_rxn_sma1, am_rxn_sma2]:\n",
    "            temp = AllChem.ReactionFromSmarts(elt, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns.append(temp)\n",
    "\n",
    "        rc_atoms = [elt.GetReactingAtoms() for elt in rxns] # Get reaction center atom idxs\n",
    "\n",
    "        # Construct rxn ctr mol objs\n",
    "        try: # REMOVE after addressing KekulizationException in get_sub_mol\n",
    "            rcs = []\n",
    "            for i, t_rxn in enumerate(rxns):\n",
    "                temp = []\n",
    "                for j, t_mol in enumerate(t_rxn.GetReactants()):\n",
    "                    temp.append(get_sub_mol(t_mol, rc_atoms[i][j]))\n",
    "                rcs.append(temp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Align substrates of the 2 reactions\n",
    "        rc_idxs = [] # Each element: (idx for rxn 1, idx for rxn 2)\n",
    "        remaining = [[i for i in range(len(elt))] for elt in rcs]\n",
    "        while (len(remaining[0]) > 0) & (len(remaining[1]) > 0):\n",
    "            idx_pair = align_substrates(rcs, remaining)\n",
    "\n",
    "            if idx_pair is None:\n",
    "                break\n",
    "            else:\n",
    "                rc_idxs.append(idx_pair)\n",
    "                remaining[0].remove(idx_pair[0])\n",
    "                remaining[1].remove(idx_pair[1])\n",
    "\n",
    "        # Skip if you haven't aligned every reactant pred to known\n",
    "        if len(rc_idxs) < len(rxn_sma1.split('>>')[0].split('.')):\n",
    "            alignment_issues.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # For reaction 2 (known reaction) Re-order rcs, rc_atoms,\n",
    "        # internal order of reactants in the reaction object in rxns\n",
    "        # and the smarts stored in the known_reactions attribute of the\n",
    "        # associated predicted reaction\n",
    "\n",
    "        # Sort reaction 2 rc_idxs by reaction 1 rc_idxs\n",
    "        rxn_1_rc_idxs, rxn_2_rc_idxs = list(zip(*rc_idxs))\n",
    "        if rxn_1_rc_idxs != rxn_2_rc_idxs:\n",
    "            rxn_2_rc_idxs, rxn_1_rc_idxs = sort_x_by_y(rxn_2_rc_idxs, rxn_1_rc_idxs)\n",
    "\n",
    "            # Re-order atom-mapped smarts string, and then update known_rxns entry\n",
    "            # with de-atom-mapped version of this string because atom mapper changes\n",
    "            # reactant order and its this order that rcs, rcatoms, rc_idxs all come from\n",
    "            am_ro_sma2 = am_rxn_sma2.split('>>')[0].split('.') # Get list of reactant strings\n",
    "            am_ro_sma2 = '.'.join([am_ro_sma2[elt] for elt in rxn_2_rc_idxs]) # Re-join in new order\n",
    "            am_rxn_sma2 = am_ro_sma2 + '>>' + am_rxn_sma2.split('>>')[1] # Join with products side\n",
    "\n",
    "            # Re-construct reaction object from re-ordered, am smarts\n",
    "            foo = rxns[1]\n",
    "            temp = AllChem.ReactionFromSmarts(am_rxn_sma2, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns[1] = temp\n",
    "            bar = rxns[1]\n",
    "\n",
    "            rc_atoms[1] = rxns[1].GetReactingAtoms() # Update rc_atoms\n",
    "            rcs[1] = [get_sub_mol(elt, rc_atoms[1][i]) for i, elt in enumerate(rxns[1].GetReactants())] # Update rc mol obj\n",
    "        \n",
    "        pred_rxns[h].known_rxns[z][1] = rm_atom_map_num(am_rxn_sma2) # Update known_reaction entry w/ de-am smarts\n",
    "        rxns = align_atom_map_nums(rxns, rcs, rc_atoms)\n",
    "\n",
    "        # Compute MCS seeded by reaction center\n",
    "        prc_mcs = get_prc_mcs(rxns, rcs, rc_atoms, norm=norm) \n",
    "        pred_rxns[h].known_rxns[z][0] = prc_mcs # Update pred_rxns\n",
    "        \n",
    "        a += 1 # Count known rxn analyzed\n",
    "        pred_rxns[h].smarts = rm_atom_map_num(am_rxn_sma1) # Update pred_rxn smarts w/ de-am smarts\n",
    "\n",
    "    print(x, ':', a / (z+1), 'of', z+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thermo\n",
    "\n",
    "# starters = 'succinate'\n",
    "# targets = 'mvacid'\n",
    "# generations = 4\n",
    "# args = ['-s', f\"{starters}\", '-t', f\"{targets}\", '-g', str(generations)]\n",
    "# command = f\"source activate /home/stef/miniconda3/envs/thermo && python /home/stef/pickaxe_thermodynamics/path_mdf.py {' '.join(args)}\"\n",
    "# subprocess.run(command, shell=True)\n",
    "\n",
    "thermo = load_json(thermo_dir + fn)\n",
    "for k,v in thermo.items():\n",
    "    st = tuple(k.split('>'))\n",
    "    for i, elt in enumerate(thermo[k]):\n",
    "        paths[st][i].mdf = elt['mdf']\n",
    "        paths[st][i].dG_opt = elt['dG_opt']\n",
    "        paths[st][i].dG_err = elt['dG_err']\n",
    "        paths[st][i].conc_opt = elt['conc_opt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reactions dict and paths list (ultimately will replace with expansion object)\n",
    "\n",
    "rxns_fn = 'predicted_reactions_' + fn\n",
    "paths_fn = 'paths_' + fn\n",
    "save_dir = '../data/processed_expansions/'\n",
    "rxns_path = save_dir + rxns_fn\n",
    "paths_path = save_dir + paths_fn\n",
    "\n",
    "with open(rxns_path, 'wb') as f:\n",
    "    pickle.dump(pred_rxns, f)\n",
    "\n",
    "with open(paths_path, 'wb') as f:\n",
    "    pickle.dump(paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25738, 1, 2357)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alignment_issues), len(pr_am_errors), len(kr_am_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
