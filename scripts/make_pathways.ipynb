{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.rxn_ctr_mcs import *\n",
    "from src.utils import load_json, rxn_entry_to_smarts, rm_atom_map_num\n",
    "from src.pathway_utils import get_reverse_paths_to_starting, create_graph_from_pickaxe\n",
    "from src.post_processing import *\n",
    "\n",
    "from minedatabase.pickaxe import Pickaxe\n",
    "from minedatabase.utils import get_compound_hash\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Intializing pickaxe object\n",
      "\n",
      "Done intializing pickaxe object\n",
      "----------------------------------------\n",
      "\n",
      "Loading ../data/pruned_expansions/succinate_to_mvacid_gen_4_tan_sample_1_n_samples_1000.pk pickled data.\n",
      "Loaded 32 compounds\n",
      "Loaded 33 reactions\n",
      "Loaded 3604 operators\n",
      "Loaded 1 targets\n",
      "Took 2.706770658493042\n"
     ]
    }
   ],
   "source": [
    "# Load processed expansion\n",
    "starters = 'succinate'\n",
    "targets = 'mvacid'\n",
    "generations = 4\n",
    "\n",
    "expansion_dir = '../data/processed_expansions/'\n",
    "thermo_dir = '../data/thermo/'\n",
    "fn = f\"{starters}_to_{targets}_gen_{generations}_tan_sample_1_n_samples_1000.pk\" # Expansion file name\n",
    "rxns_path = expansion_dir + 'predicted_reactions_' + fn\n",
    "paths_path = expansion_dir + 'paths_' + fn\n",
    "pruned_dir = '../data/pruned_expansions/'\n",
    "\n",
    "# Load reactions and paths\n",
    "with open(rxns_path, 'rb') as f:\n",
    "    pred_rxns = pickle.load(f)\n",
    "\n",
    "with open(paths_path, 'rb') as f:\n",
    "    paths = pickle.load(f)\n",
    "\n",
    "# Load raw expansion object\n",
    "pk = Pickaxe()\n",
    "path = pruned_dir + fn\n",
    "pk.load_pickled_pickaxe(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('succinate', 'mvacid') 41\n"
     ]
    }
   ],
   "source": [
    "for k,v in paths.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in IMT rule mapping\n",
    "\n",
    "# Load rules\n",
    "rules_path = '../data/rules/JN3604IMT_rules.tsv'\n",
    "rule_df = pd.read_csv(rules_path, delimiter='\\t')\n",
    "rule_df.set_index('Name', inplace=True)\n",
    "\n",
    "# Load mapping\n",
    "rxn2rule = {}\n",
    "db_names = ['_mc_v21', '_brenda', '_kegg']\n",
    "suffix = '_imt_rules_enforce_cof.csv'\n",
    "for name in db_names:\n",
    "    mapping_path = '../data/mapping/mapping' + name + suffix\n",
    "    with open(mapping_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if len(row) == 1:\n",
    "                rxn2rule[row[0]] = []\n",
    "            else:\n",
    "                rxn2rule[row[0]] = row[1:]\n",
    "\n",
    "# Make rule2rxn\n",
    "rule2rxn = {}\n",
    "for k,v in rxn2rule.items():\n",
    "    for elt in v:\n",
    "        if elt not in rule2rxn:\n",
    "            rule2rxn[elt] = [k]\n",
    "        else:\n",
    "            rule2rxn[elt].append(k)\n",
    "\n",
    "# Load all known reaction json entries into dict\n",
    "known_rxns = {}\n",
    "pref = '../data/mapping/'\n",
    "suffs = ['mc_v21_as_is.json', 'brenda_as_is.json', 'kegg_as_is.json']\n",
    "for elt in suffs:\n",
    "    known_rxns.update(load_json(pref + elt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate reaction objects in rxn dict w/ known reactions\n",
    "\n",
    "for k, v in pred_rxns.items():\n",
    "    this_rules = list(pk.reactions[k][\"Operators\"])\n",
    "    this_known_rxns = []\n",
    "    for elt in this_rules:\n",
    "        if elt in rule2rxn:\n",
    "            this_rxn_ids = rule2rxn[elt]\n",
    "            for this_id in this_rxn_ids:\n",
    "                this_sma = rxn_entry_to_smarts(known_rxns[this_id])\n",
    "                this_known_rxns.append((None, this_sma, this_id))\n",
    "    \n",
    "    v.known_rxns = [list(elt) for elt in set(this_known_rxns)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "('succinate', 'mvacid') 41\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_rxns))\n",
    "for k,v in paths.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 0.15 of 40\n",
      "2 : 0.6086956521739131 of 23\n",
      "3 : 0.0 of 88\n",
      "4 : 1.0 of 24\n",
      "5 : 0.13636363636363635 of 88\n",
      "6 : 0.6086956521739131 of 23\n",
      "7 : 0.6086956521739131 of 23\n",
      "8 : 1.0 of 24\n",
      "9 : 1.0 of 18\n",
      "10 : 0.723404255319149 of 47\n",
      "11 : 1.0 of 20\n",
      "12 : 1.0 of 9\n",
      "13 : 0.9310344827586207 of 29\n",
      "14 : 0.15 of 40\n",
      "15 : 0.13636363636363635 of 88\n",
      "16 : 0.9310344827586207 of 29\n",
      "17 : 1.0 of 20\n",
      "19 : 0.13636363636363635 of 88\n",
      "20 : 1.0 of 9\n",
      "21 : 1.0 of 18\n",
      "22 : 0.723404255319149 of 47\n",
      "23 : 0.13636363636363635 of 88\n",
      "24 : 0.15 of 40\n",
      "26 : 0.13636363636363635 of 88\n",
      "27 : 0.15 of 40\n",
      "28 : 1.0 of 18\n",
      "29 : 0.15 of 40\n",
      "30 : 0.0 of 40\n",
      "31 : 0.13636363636363635 of 88\n",
      "32 : 0.15 of 40\n"
     ]
    }
   ],
   "source": [
    "pr_am_errors = [] # Track predicted rxn am errors\n",
    "kr_am_errors = [] # Track known rxn am errors\n",
    "alignment_issues = [] # Track substrate alignment issues\n",
    "norm = 'max atoms' # Normalize MCS atom count by larger molecule\n",
    "\n",
    "# Populate pred_rxns, known rxn prc-mcs slot\n",
    "# for x in range(1):\n",
    "for x in range(len(pred_rxns.keys())):\n",
    "    h = list(pred_rxns.keys())[x]\n",
    "    rxn_sma1 = pred_rxns[h].smarts\n",
    "\n",
    "    # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "    try:\n",
    "        am_rxn_sma1 = atom_map(rxn_sma1)\n",
    "    except:\n",
    "        pr_am_errors.append(h)\n",
    "        continue\n",
    "\n",
    "    a = 0 # Number known rxns analyzed\n",
    "    for z, kr in enumerate(pred_rxns[h].known_rxns):\n",
    "        rxn_sma2 = kr[1]\n",
    "\n",
    "        # Catch stoichiometry mismatches stemming from pickaxe, early post-processing\n",
    "        if tuple([len(elt.split('.')) for elt in rxn_sma2.split('>>')]) != tuple([len(elt.split('.')) for elt in rxn_sma1.split('>>')]):\n",
    "            print(x, z, 'stoich_error')\n",
    "            continue\n",
    "\n",
    "        # Skip pred reactions that trigger RXNMapper atom mapping errors\n",
    "        try:\n",
    "            am_rxn_sma2 = atom_map(rxn_sma2)\n",
    "        except:\n",
    "            kr_am_errors.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # Construct reaction objects\n",
    "        rxns = []\n",
    "        for elt in [am_rxn_sma1, am_rxn_sma2]:\n",
    "            temp = AllChem.ReactionFromSmarts(elt, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns.append(temp)\n",
    "\n",
    "        rc_atoms = [elt.GetReactingAtoms() for elt in rxns] # Get reaction center atom idxs\n",
    "\n",
    "        # Construct rxn ctr mol objs\n",
    "        try: # REMOVE after addressing KekulizationException in get_sub_mol\n",
    "            rcs = []\n",
    "            for i, t_rxn in enumerate(rxns):\n",
    "                temp = []\n",
    "                for j, t_mol in enumerate(t_rxn.GetReactants()):\n",
    "                    temp.append(get_sub_mol(t_mol, rc_atoms[i][j]))\n",
    "                rcs.append(temp)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Align substrates of the 2 reactions\n",
    "        rc_idxs = [] # Each element: (idx for rxn 1, idx for rxn 2)\n",
    "        remaining = [[i for i in range(len(elt))] for elt in rcs]\n",
    "        while (len(remaining[0]) > 0) & (len(remaining[1]) > 0):\n",
    "            idx_pair = align_substrates(rcs, remaining)\n",
    "\n",
    "            if idx_pair is None:\n",
    "                break\n",
    "            else:\n",
    "                rc_idxs.append(idx_pair)\n",
    "                remaining[0].remove(idx_pair[0])\n",
    "                remaining[1].remove(idx_pair[1])\n",
    "\n",
    "        # Skip if you haven't aligned every reactant pred to known\n",
    "        if len(rc_idxs) < len(rxn_sma1.split('>>')[0].split('.')):\n",
    "            alignment_issues.append((h, z, kr[-1]))\n",
    "            continue\n",
    "\n",
    "        # For reaction 2 (known reaction) Re-order rcs, rc_atoms,\n",
    "        # internal order of reactants in the reaction object in rxns\n",
    "        # and the smarts stored in the known_reactions attribute of the\n",
    "        # associated predicted reaction\n",
    "\n",
    "        # Sort reaction 2 rc_idxs by reaction 1 rc_idxs\n",
    "        rxn_1_rc_idxs, rxn_2_rc_idxs = list(zip(*rc_idxs))\n",
    "        if rxn_1_rc_idxs != rxn_2_rc_idxs:\n",
    "            rxn_2_rc_idxs, rxn_1_rc_idxs = sort_x_by_y(rxn_2_rc_idxs, rxn_1_rc_idxs)\n",
    "\n",
    "            # Re-order atom-mapped smarts string, and then update known_rxns entry\n",
    "            # with de-atom-mapped version of this string because atom mapper changes\n",
    "            # reactant order and its this order that rcs, rcatoms, rc_idxs all come from\n",
    "            am_ro_sma2 = am_rxn_sma2.split('>>')[0].split('.') # Get list of reactant strings\n",
    "            am_ro_sma2 = '.'.join([am_ro_sma2[elt] for elt in rxn_2_rc_idxs]) # Re-join in new order\n",
    "            am_rxn_sma2 = am_ro_sma2 + '>>' + am_rxn_sma2.split('>>')[1] # Join with products side\n",
    "\n",
    "            # Re-construct reaction object from re-ordered, am smarts\n",
    "            foo = rxns[1]\n",
    "            temp = AllChem.ReactionFromSmarts(am_rxn_sma2, useSmiles=True)\n",
    "            temp.Initialize()\n",
    "            rxns[1] = temp\n",
    "            bar = rxns[1]\n",
    "\n",
    "            rc_atoms[1] = rxns[1].GetReactingAtoms() # Update rc_atoms\n",
    "            rcs[1] = [get_sub_mol(elt, rc_atoms[1][i]) for i, elt in enumerate(rxns[1].GetReactants())] # Update rc mol obj\n",
    "        \n",
    "        pred_rxns[h].known_rxns[z][1] = rm_atom_map_num(am_rxn_sma2) # Update known_reaction entry w/ de-am smarts\n",
    "        rxns = align_atom_map_nums(rxns, rcs, rc_atoms)\n",
    "\n",
    "        # Compute MCS seeded by reaction center\n",
    "        prc_mcs = get_prc_mcs(rxns, rcs, rc_atoms, norm=norm) \n",
    "        pred_rxns[h].known_rxns[z][0] = prc_mcs # Update pred_rxns\n",
    "        \n",
    "        a += 1 # Count known rxn analyzed\n",
    "        pred_rxns[h].smarts = rm_atom_map_num(am_rxn_sma1) # Update pred_rxn smarts w/ de-am smarts\n",
    "\n",
    "    print(x, ':', a / (z+1), 'of', z+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: source: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='source activate /home/stef/miniconda3/envs/thermo && python /home/stef/pickaxe_thermodynamics/path_mdf.py -s succinate -t mvacid -g 4', returncode=127)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Thermo\n",
    "\n",
    "starters = 'succinate'\n",
    "targets = 'mvacid'\n",
    "generations = 4\n",
    "args = ['-s', f\"{starters}\", '-t', f\"{targets}\", '-g', str(generations)]\n",
    "command = f\"source activate /home/stef/miniconda3/envs/thermo && python /home/stef/pickaxe_thermodynamics/path_mdf.py {' '.join(args)}\"\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "# thermo = load_json(thermo_dir + fn)\n",
    "# for k,v in thermo.items():\n",
    "#     st = tuple(k.split('>'))\n",
    "#     for i, elt in enumerate(thermo[k]):\n",
    "#         paths[st][i].mdf = elt['mdf']\n",
    "#         paths[st][i].dG_opt = elt['dG_opt']\n",
    "#         paths[st][i].dG_err = elt['dG_err']\n",
    "#         paths[st][i].conc_opt = elt['conc_opt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reactions dict and paths list (ultimately will replace with expansion object)\n",
    "\n",
    "rxns_fn = 'predicted_reactions_' + fn\n",
    "paths_fn = 'paths_' + fn\n",
    "save_dir = '../data/processed_expansions/'\n",
    "rxns_path = save_dir + rxns_fn\n",
    "paths_path = save_dir + paths_fn\n",
    "\n",
    "with open(rxns_path, 'wb') as f:\n",
    "    pickle.dump(pred_rxns, f)\n",
    "\n",
    "with open(paths_path, 'wb') as f:\n",
    "    pickle.dump(paths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 3, 113)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alignment_issues), len(pr_am_errors), len(kr_am_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
